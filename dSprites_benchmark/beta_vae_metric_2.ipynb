{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "beta-vae metric.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzJpuBwlF-c5",
        "colab_type": "code",
        "outputId": "97307689-c72c-46f3-a762-ba30f4aaed18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%matplotlib inline\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import math\n",
        "import typing\n",
        "import tqdm\n",
        "import os\n",
        "import itertools\n",
        "import copy\n",
        "import subprocess\n",
        "\n",
        "from pathlib import Path\n",
        "from enum import IntEnum\n",
        "from sklearn.decomposition import FastICA\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(231)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDKTUTpmHHN3",
        "colab_type": "text"
      },
      "source": [
        "# Build a model according to specification (Tbl. 1 Higgins et al.)\n",
        "* **Input**  4096 (flattened 64x64x1).\n",
        "* **Encoder**  FC 1200, 1200. ReLU activation.\n",
        "* **Latents**  10\n",
        "* **Decoder**  FC 1200, 1200, 1200, 4096. Tanh activation. Bernoulli.\n",
        "* **Optimiser** Adagrad 1e-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ1GDvnQGKjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VAE(tf.keras.Model):\n",
        "    def __init__(self, latent_dim=10):\n",
        "        super(VAE, self).__init__()\n",
        "        self._latent_dim = latent_dim\n",
        "        self.encoder = tf.keras.Sequential([\n",
        "            tf.keras.layers.InputLayer((64, 64, 1)),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(1200, activation='relu'),\n",
        "            tf.keras.layers.Dense(1200, activation='relu'),\n",
        "            tf.keras.layers.Dense(latent_dim * 2)\n",
        "        ])\n",
        "        self.decoder = tf.keras.Sequential([\n",
        "            tf.keras.layers.InputLayer(latent_dim),\n",
        "            tf.keras.layers.Dense(1200, activation='tanh'),\n",
        "            tf.keras.layers.Dense(1200, activation='tanh'),\n",
        "            tf.keras.layers.Dense(1200, activation='tanh'),\n",
        "            tf.keras.layers.Dense(4096),\n",
        "            tf.keras.layers.Reshape((64, 64, 1))\n",
        "        ])\n",
        "\n",
        "    def call(self, x): raise NotImplementedError\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = self.encoder(x)\n",
        "        mean, logvar = tf.split(h, num_or_size_splits=2, axis=1)\n",
        "        return self.reparameterise(mean, logvar), mean, logvar\n",
        "    \n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    @staticmethod\n",
        "    def reparameterise(mean, logvar):\n",
        "        # log sig^2 = 2 log sig => exp(1/2 log sig^2) = exp(log sig) = sig\n",
        "        eps = tf.random.normal(mean.shape, mean=0.0, stddev=1.0)\n",
        "        return mean + tf.exp(logvar * 0.5) * eps\n",
        "\n",
        "BETA = 4\n",
        "EPOCHS = 100\n",
        "LATENT_DIM = 10\n",
        "BATCH_SIZE = 32\n",
        "TR_SIZE = 550_000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOgyQAxGIVbz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PCA:\n",
        "    def __init__(self, latent_dim: int, ds: 'DSprites', subset: int=100_000):\n",
        "        x = ds.subset(subset)\n",
        "        self._width = x.shape[1]\n",
        "        self._height = x.shape[2]\n",
        "        self.mean = np.mean(x, axis=0)\n",
        "        self._latent_dim = latent_dim\n",
        "        self._D = self._width * self._height\n",
        "        x = (x - self.mean).reshape(-1, self._D)\n",
        "        self._e, V = tf.linalg.eigh(tf.matmul(x.T, x))\n",
        "        assert V.shape == (self._D, self._D)\n",
        "        # non-decreasing => take the last latent_dim cols!\n",
        "        self.V_k = V[:, -self._latent_dim:]\n",
        "    \n",
        "    def encode(self, x):\n",
        "        x = (x - self.mean).reshape(-1, self._D)\n",
        "        z = tf.matmul(x, self.V_k)\n",
        "        assert z.shape == (x.shape[0], self._latent_dim)\n",
        "        # our VAE encoders return z, mean, logvar\n",
        "        # and our data generator takes the mean (see generate_benchmarking_dataset)\n",
        "        # so we have to return z in the middle of a 3-tuple\n",
        "        return z, z, None\n",
        "    \n",
        "    def decode(self, z):\n",
        "        return tf.matmul(z, self.V_k, transpose_b=True).numpy().reshape(-1, self._width, self._height, 1) # + self.mean\n",
        "\n",
        "    @property\n",
        "    def explained_variance_ratio(self):\n",
        "        e = self._e.numpy()[::-1]       \n",
        "        return e[: self._latent_dim]/sum(e)\n",
        "\n",
        "class ICA:\n",
        "    def __init__(self, latent_dim: int, ds: 'DSprites', subset: int=100_000):\n",
        "        x = ds.subset(subset)\n",
        "        self._width = x.shape[1]\n",
        "        self._height = x.shape[2]\n",
        "        self._D = self._width * self._height\n",
        "        self._model = FastICA(n_components=latent_dim)\n",
        "        self._model.fit(x.reshape(-1, self._D))\n",
        "\n",
        "    def encode(self, x):\n",
        "        z = self._model.transform(x.reshape(-1, self._D))\n",
        "        return z, z, None\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self._model.inverse_transform(z).reshape(-1, self._width, self._height, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X1zJ6n8HQ1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DSprites:\n",
        "    class Latents(IntEnum):\n",
        "        COLOUR, SHAPE, SCALE, ORIENTATION, XPOS, YPOS = range(6)\n",
        "        \n",
        "    \"\"\"\n",
        "    A significant portion of this class is taken as-is from the manual\n",
        "    https://github.com/deepmind/dsprites-dataset/blob/master/dsprites_reloading_example.ipynb\n",
        "    \"\"\"\n",
        "    def __init__(self, path=\".\", download=False):\n",
        "        self._filename = 'dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz'\n",
        "        path = Path(path).absolute()\n",
        "        assert path.exists()\n",
        "        data = path / self._filename\n",
        "        if not data.exists():\n",
        "            if download:\n",
        "                subprocess.run([\"wget\", \"-O\", str(data),\n",
        "                                \"https://github.com/deepmind/dsprites-dataset/raw/master/dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz\"])\n",
        "            else:\n",
        "                raise ValueException(\"Can't find dataset, use download=True to download.\")\n",
        "        data = np.load(str(data), encoding='bytes', allow_pickle=True)\n",
        "\n",
        "        # ====\n",
        "\n",
        "        imgs = data['imgs']\n",
        "        metadata_raw = data['metadata'][()]\n",
        "        self._metadata = dict()\n",
        "        for k, v in metadata_raw.items():\n",
        "            self._metadata[k.decode()] = v\n",
        "\n",
        "        # NOTE: can't cast now because our notebook runs out of RAM. cast in map instead\n",
        "        # imgs = imgs.reshape(-1, 64, 64, 1).astype(np.float32)\n",
        "        self._imgs = imgs.reshape(-1, 64, 64, 1)\n",
        "\n",
        "        # for example: array([ 0,  0,  2, 37, 15, 22])\n",
        "        # i.e. the relative (normalised) change in latent factors\n",
        "        self._latents_classes = data['latents_classes']\n",
        "\n",
        "        # for example: array([1., 1., 0.7 , 5.96097068, 0.48387097, 0.70967742])\n",
        "        # i.e. the actual latent values used to generate the image\n",
        "        self._latents_values = data['latents_values']\n",
        "\n",
        "        # specification: the number of varying \"degrees\" of change in each\n",
        "        # dimension corresponding to an independent generative factor\n",
        "        # array([ 1,        3,      6,           40,  32,  32])\n",
        "        #       colour, shape,  scale,  orientation,   X,   Y\n",
        "        self._latents_sizes = self._metadata['latents_sizes']\n",
        "\n",
        "        # for easy conversion from latent vector to indices later (see latent_to_idx)\n",
        "        # essentially: array([737280, 245760,  40960,   1024,     32,      1])\n",
        "        self._latents_bases = np.r_[self._latents_sizes[::-1].cumprod()[::-1][1:], 1]\n",
        "    \n",
        "    def latent_size(self, latent: 'DSprites.Latents') -> int:\n",
        "        \"\"\"\n",
        "        :param latent: of type DSprites.Latents (an enum class)\n",
        "        :return: the maximum integer allowed for the specified `latent`\n",
        "        \"\"\"\n",
        "        return self._latents_sizes[latent.value]\n",
        "    \n",
        "    def to_idx(self, latents: np.array) -> int:\n",
        "        \"\"\"\n",
        "        convert latent vector into index that can then be used to index\n",
        "        the actual image in self._imgs\n",
        "        \"\"\"\n",
        "        return np.dot(latents, self._latents_bases).astype(int)\n",
        "    \n",
        "    def sample_latent(self, n: int=1, fixed: 'DSprites.Latents'=None) -> np.array:\n",
        "        \"\"\"\n",
        "        randomly samples `n` latent vectors\n",
        "\n",
        "        :param n: number samples\n",
        "        :param fixed: if not `None`, then in all samples, this latent is kept\n",
        "                     fixed based on a random draw. The rest of the latents are\n",
        "                     random.\n",
        "        :return: an `np.array` of shape nx6\n",
        "        \"\"\"\n",
        "        samples = np.zeros((n, self._latents_sizes.shape[0]))\n",
        "        for i, lat_size in enumerate(self._latents_sizes):\n",
        "            samples[:, i] = np.random.randint(lat_size, size=n)\n",
        "        if fixed:\n",
        "            samples[:, fixed] = np.random.randint(0, ds.latent_size(fixed))\n",
        "        return samples\n",
        "    \n",
        "    @property\n",
        "    def imgs(self) -> np.array:\n",
        "        return self._imgs\n",
        "\n",
        "    def subset(self, size=50_000) -> np.array:\n",
        "        \"\"\"\n",
        "        returns a subset of the images. (Workaround for memory constraints)\n",
        "        :param size: number of samples to return\n",
        "        \"\"\"\n",
        "        return self._imgs[np.random.choice(self._imgs.shape[0], size=size, replace=False)]\n",
        "\n",
        "def make_grid(tensor: np.array, nrow: int=8, padding: int=2, pad_value: int=0) -> np.array:\n",
        "    \"\"\"\n",
        "    adapted from: https://pytorch.org/docs/stable/_modules/torchvision/utils.html#make_grid\n",
        "    :param tensor: nxwxhxc np.array\n",
        "    :param nrow: number of images displayed in each row\n",
        "    :param padding: padding between images\n",
        "    :param pad_value: value used to pad\n",
        "    :return: np.array of dimension 3 (WxHxC) with all images arranged in a grid.\n",
        "\n",
        "    \"\"\"\n",
        "    if tensor.shape[0] == 1:\n",
        "        return tensor.squeeze()\n",
        "\n",
        "    # make the mini-batch of images into a grid\n",
        "    nmaps = tensor.shape[0]\n",
        "    xmaps = min(nrow, nmaps)\n",
        "    ymaps = int(math.ceil(float(nmaps) / xmaps))\n",
        "    height, width = int(tensor.shape[1] + padding), int(tensor.shape[2] + padding)\n",
        "    num_channels = tensor.shape[3]\n",
        "    grid = np.full((height * ymaps + padding, width * xmaps + padding, num_channels), pad_value, dtype=tensor.dtype)\n",
        "    k = 0\n",
        "    for y in range(ymaps):\n",
        "        for x in range(xmaps):\n",
        "            if k >= nmaps: break\n",
        "            ystart = y * height + padding\n",
        "            xstart = x * width + padding\n",
        "            grid[ystart:(ystart + height - padding), ...][:, xstart:(xstart + width - padding), :] = tensor[k]\n",
        "            k = k + 1\n",
        "    return grid.squeeze()\n",
        "\n",
        "def imshow(img: np.array, title: str='', ax: plt.Axes=None):\n",
        "    if not ax:\n",
        "        fig = plt.figure(figsize=(15, 15))\n",
        "        ax = fig.add_subplot(111)\n",
        "    ax.imshow(img, cmap='gray', interpolation='nearest')\n",
        "    ax.set_xticks(())\n",
        "    ax.set_yticks(())\n",
        "    if title:\n",
        "        ax.set_title(title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOXYY5EvHmIV",
        "colab_type": "code",
        "outputId": "030426c2-84a9-4930-846c-aafd20c0793e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "ds = DSprites(download=True)\n",
        "test_batch = ds.subset(size=32)\n",
        "imshow(make_grid(test_batch))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1YAAAG1CAYAAAD6E2VuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEBKsAAAAQv8FX06X57ZKr1AAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x1080 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uioks1JIIQzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca = PCA(LATENT_DIM, ds, subset=75_000)\n",
        "print(pca.explained_variance_ratio)\n",
        "print(sum(pca.explained_variance_ratio))\n",
        "\n",
        "# simple sanity check\n",
        "z, *_ = pca.encode(test_batch)\n",
        "fig = plt.figure(figsize=(15, 15))\n",
        "ax1 = fig.add_subplot(121)\n",
        "ax2 = fig.add_subplot(122)\n",
        "imshow(make_grid(test_batch), title='Original', ax=ax1)\n",
        "imshow(make_grid(pca.decode(z)), title='Reconstructed', ax=ax2)\n",
        "fig.subplots_adjust(wspace=0.01)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjtSJfkbH6hk",
        "colab_type": "code",
        "outputId": "f61d13d1-88d3-48fc-e1f1-c7db549c9169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        }
      },
      "source": [
        "vae4 = VAE(LATENT_DIM)\n",
        "# load pretrained model with 100 epochs (from 550k randomly sampled points)\n",
        "vae4.load_weights(f'./vae4/vae4_e100_550000')\n",
        "\n",
        "z, *_ = vae4.encode(test_batch)\n",
        "fig = plt.figure(figsize=(15, 15))\n",
        "ax1 = fig.add_subplot(121)\n",
        "ax2 = fig.add_subplot(122)\n",
        "imshow(make_grid(test_batch), title='Original', ax=ax1)\n",
        "imshow(make_grid(tf.nn.sigmoid(vae4.decode(z)).numpy()), title='Reconstructed', ax=ax2)\n",
        "fig.subplots_adjust(wspace=0.01)\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1YAAADyCAYAAABOOVQOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2uxkcl4ZAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfoUuUazrRhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vae1 = VAE(LATENT_DIM)\n",
        "# load pretrained model with 100 epochs (from 550k randomly sampled points)\n",
        "vae1.load_weights(f'./vae1/vae1_e100_550000')\n",
        "\n",
        "# simple sanity check\n",
        "z, *_ = vae1.encode(test_batch)\n",
        "fig = plt.figure(figsize=(15, 15))\n",
        "ax1 = fig.add_subplot(121)\n",
        "ax2 = fig.add_subplot(122)\n",
        "imshow(make_grid(test_batch), title='Original', ax=ax1)\n",
        "imshow(make_grid(tf.nn.sigmoid(vae1.decode(z)).numpy()), title='Reconstructed', ax=ax2)\n",
        "fig.subplots_adjust(wspace=0.01)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZKZbsDCrilT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vae_untrained = VAE(LATENT_DIM)\n",
        "\n",
        "z, *_ = vae_untrained.encode(test_batch)\n",
        "fig = plt.figure(figsize=(15, 15))\n",
        "ax1 = fig.add_subplot(121)\n",
        "ax2 = fig.add_subplot(122)\n",
        "imshow(make_grid(test_batch), title='Original', ax=ax1)\n",
        "imshow(make_grid(tf.nn.sigmoid(vae_untrained.decode(z)).numpy()), title='Reconstructed', ax=ax2)\n",
        "fig.subplots_adjust(wspace=0.01)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqe-N9Kzf7xy",
        "colab_type": "text"
      },
      "source": [
        "# Generating $z^b_{diff}$\n",
        "\n",
        "for batch $b$ = 1 ... B:\n",
        "   1. sample $y_b$ from Unif(SCALE, XPOS, YPOS, ORIENTATION)\n",
        "   2. repeat L times to get $z^{l=1}_{diff}$, $\\dots$, $z^{l=L}_{diff}$:\n",
        "   \n",
        "        (a) sample latents vectors $v_{1, l}$ and $v_{2, l}$ where the value in the dimension corresponding to $y_b$ is kept fixed.\n",
        "\n",
        "        (b) generate images $x_{1, l}$ and $x_{2, l}$ from $Sim(v_{1, l})$ and $Sim(v_{2, l})$\n",
        "\n",
        "        (c) calculate $z_{1, l} = \\mu(x_{1, l})$ where $\\mu(.)$ is the (neural network) encoder portion that is responsible for outputting the mean of the posterior $q_\\phi(\\mathbf z| \\mathbf x) = \\mathcal N\\left(\\mathbf z; \\mu(\\mathbf x), \\Sigma(\\mathbf x)\\right)$; likewise $z_{2,l} = \\mu(x_{2, l})$ \n",
        "\n",
        "        (d) finally, calculate $z^l_{diff} = |z_{1, 1} - z_{2,l}|$\n",
        "\n",
        "3. we obtain $z^b_{diff} = \\frac{1}{L}\\sum_l^L z^l_{diff}$\n",
        "\n",
        "The `generate_benchmarking_dataset` function then returns $z^{b=1}_{diff}, \\dots, z^{b=B}_{diff}$  and their corresponding fixed latents $y_b$.\n",
        "\n",
        "> Note that **colour** and **shape** are not evaluated. **Colour** is understandable as all\n",
        "images are white, however, **shape** is conspicously left out, perhaps because the paper (and in our reproduced result) shows that none of the learnt latents encode **shape**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-M_RuyvIXsU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_benchmarking_dataset(model: VAE,\n",
        "                                  ds: DSprites, l: int,\n",
        "                                  batches: int,\n",
        "                                  with_shapes: bool=False) -> typing.Tuple[np.array, np.array]:\n",
        "    \"\"\"\n",
        "    :param model: must have an `encode` function that takes a tensor of shape\n",
        "                  N x W x H x C and returns a tuple (z, mean, logvar)\n",
        "                  where all three elements are of shape N x LATENT_DIM\n",
        "    :param ds: DSprites dataset                 \n",
        "    :param l: number of samples to draw for a given fixed latent. Corresponds\n",
        "              to the same L described in the paper.\n",
        "    :param batches: number of batches. Corresponds to the same B\n",
        "                    described in the paper.\n",
        "    :param with_shapes: should shapes be included as a fixed latent or ignored?\n",
        "                        By default it is ignored as the paper did too.\n",
        "    :return: a tuple of x and y where x is an array of shape  b x LATENT_DIM\n",
        "             and y is an array of length b. That is, x[b] = z^b_diff.\n",
        "    \"\"\"                                \n",
        "    x = []\n",
        "    y = []\n",
        "    # here, each batch is allowed to fix a different latent factor\n",
        "    for b in tqdm.trange(batches):\n",
        "        # low=2 because 0 is COLOUR which is always fixed and 1 is SHAPE\n",
        "        # but the paper doesn't evaluate SHAPEs\n",
        "        least_latent_idx = 1 if with_shapes else 2\n",
        "        y_fixed = DSprites.Latents(\n",
        "            np.random.randint(low=least_latent_idx, high=6, size=1)\n",
        "        )\n",
        "        assert y_fixed != DSprites.Latents.COLOUR and (with_shapes or y_fixed != DSprites.Latents.SHAPE)\n",
        "\n",
        "        # 2*l x LATENT_DIM: 2*l because for each l we take the difference of 2 Zs\n",
        "        _, mean, _ = model.encode(\n",
        "            ds.imgs[ds.to_idx(ds.sample_latent(n=(2 * l), fixed=y_fixed))]\n",
        "        )\n",
        "\n",
        "        # z_{1,l} = mean(x_{1,l}); z_{2,l} = mean(x_{2,l})\n",
        "        # z^b_diff = average_l(z^l_diff) where z^l_diff = |z_{1,l} - z_{2,l}|\n",
        "\n",
        "        zldiff = np.array([tf.abs(mean[i] - mean[i + 1]).numpy() for i in range(0, 2 * l, 2)])\n",
        "        assert zldiff.shape == (l, mean.shape[1])\n",
        "        zbdiff = np.mean(zldiff, axis=0)\n",
        "        assert zbdiff.shape == (mean.shape[1], )\n",
        "        x.append(zbdiff)\n",
        "        assert y_fixed.value >= least_latent_idx\n",
        "        # the integers are expected to start from 0 but we start from low=least_latent_idx\n",
        "        # hence, we have to shift it.\n",
        "        y.append(y_fixed.value - least_latent_idx)\n",
        "    return np.array(x), np.array(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U0tlg8RgHFt",
        "colab_type": "text"
      },
      "source": [
        "# Quantitative measure: Linear classifer\n",
        "\n",
        "From Higgins et al. (2017):\n",
        "> We used a fully connected linear classifier to predict $p(y|\\mathbf z^b_{diff})$, where y is one of four generative factors (position X, position Y, scale\n",
        "and rotation). We used softmax output nonlinearity and a negative log likelihood loss function. The classifier was trained using the Adagrad (Duchi et al., 2011) optimisation algorithm with learning rate of 1e-2 until convergence.\n",
        "\n",
        "The code below is an exact translation of the excerpt above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQDYCGzNru9A",
        "colab_type": "code",
        "outputId": "c838f5b4-ddf8-46b4-cdc2-a64634c0d225",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "def get_linear_classifier(num_classes=4, input_dim=LATENT_DIM) -> tf.keras.Model:\n",
        "    \"\"\"\n",
        "    :param num_classes: number of output classes. By default, there are\n",
        "                        four: XPOS, YPOS, SCALE, ORIENTATION/ROTATION.\n",
        "    :return: keras model. A linear classifier that's essentially a multiclass\n",
        "             logistic regression.\n",
        "    \"\"\"\n",
        "    model = tf.keras.Sequential([\n",
        "       tf.keras.layers.InputLayer((input_dim,)),\n",
        "       tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=1e-2),\n",
        "                  loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "get_linear_classifier().summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              (None, 4)                 44        \n",
            "=================================================================\n",
            "Total params: 44\n",
            "Trainable params: 44\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6l9oCCIxYxI",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating the models\n",
        "\n",
        "In this experiement, we'll reproduce the results for $\\beta$-vae, regular vae, and PCA. From the paper, it states that\n",
        "\"[t]en replicas of each model with the same hyperparameters were trained using different random seeds to obtain disentangled representations. Each of the ten trained model replicas was evaluated three times using the disentanglement metric score algorithm, each time using a different random seed to initialise the linear classifier. We then discarded the bottom 50% of the thirty resulting scores and reported the remaining results. This was done to control for the outlier results from the few experiments that diverged during training.\".\n",
        "\n",
        "In summary, there are ten independent copies of each model each trained separately (different seeds used for weight initializations) but identically. Next, each of the ten models are evaulated thrice using the linear classifier and the bottom 50% of the thirty resulting scores are discarded.\n",
        "\n",
        "Here, instead of having ten independent copies of the models, we'll have one each but evaluated three times using the linear classifier. Therefore, instead of thirty scores per model, we will only have three. *Arguably, as long as our results do not diverge, a single model should suffice.*\n",
        "\n",
        "Later, we will also evaluate the models **with** shape included as the fixed generative factor to see how it affects the metric, despite none of the $z_i$s showing that it identified shape as an independent latent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bjBLwIUsHZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# how many times to repeat the experiment. Each repetition creates a\n",
        "# new linear classifier with different initial values\n",
        "REPEAT = 3\n",
        "# in each batch, we take the average of L zdiffs\n",
        "L = 64\n",
        "# take B batches, i.e. creating a dataset of size (B, LATENT_DIM)\n",
        "B = 10_000\n",
        "# section 4.2: The table in Fig. 6 (left) reports the classification accuracy of the disentanglement metric for 5,000 test samples\n",
        "E = 5_000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCkGM3E82sFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_experiment(model: VAE, ds: DSprites, l: int, batches: int, test_batch: int,\n",
        "                   reps: int, with_shapes: bool=False, \n",
        "                   latent_subset: typing.Optional[typing.List[int]]=None,\n",
        "                   verbose: int=1) -> np.array:\n",
        "    \"\"\"\n",
        "    :param model: must have an `encode` function that takes a tensor of shape\n",
        "                  N x W x H x C and returns a tuple (z, mean, logvar)\n",
        "                  where all three elements are of shape N x LATENT_DIM\n",
        "    :param ds: DSprites object used to generate dataset                 \n",
        "    :param l: number of samples to draw for a given fixed latent. Corresponds\n",
        "              to the same L described in the paper.\n",
        "    :param batches: number of batches. Corresponds to the same B\n",
        "                    described in the paper.\n",
        "    :param test_batch: number of test batch. The paper used 5,000 test points\n",
        "                       to evulate the accuracy of the linear classifier.                   \n",
        "    :param reps: number of times to repeat this experiment.\n",
        "    :param with_shapes: should shapes be included as a latent factor that should\n",
        "                        be measured?\n",
        "    :param latent_subset: If none, all `LATENT_DIM` dimensions are used. Otherwise,\n",
        "                          will use the provided list to index the subset of\n",
        "                          dimensions desired: `z[:, latent_subset]`.\n",
        "    :param verbose: verbosity level of model.fit(..., verbose) where model\n",
        "                    is of type `tf.keras.Model`.\n",
        "    :return: an np.array of accuracies. This array is of length `reps`, where\n",
        "             each element corresponds to the maximum accuracy\n",
        "             obtained during training for that particular iteration.\n",
        "    \"\"\"\n",
        "    # create data (z^b_diff)s\n",
        "    x_train, y_train = generate_benchmarking_dataset(model, ds,\n",
        "                                                     l=l, batches=(batches + test_batch),\n",
        "                                                     with_shapes=with_shapes)\n",
        "    if latent_subset:\n",
        "        x_train = x_train[:, latent_subset]                                                    \n",
        "    x_train = x_train[: batches]\n",
        "    y_train = y_train[: batches]\n",
        "    x_test = x_train[-test_batch:]\n",
        "    y_test = y_train[-test_batch:]\n",
        "\n",
        "    assert x_train.shape == (B, len(latent_subset) if latent_subset else LATENT_DIM) and y_train.shape == (B, )\n",
        "    assert x_test.shape == (E, len(latent_subset) if latent_subset else LATENT_DIM) and y_test.shape == (E, )\n",
        "    assert ((y_train < (5 if with_shapes else 4)) & (y_train >= 0)).all()\n",
        "    assert ((y_test < (5 if with_shapes else 4)) & (y_test >= 0)).all()\n",
        "    \n",
        "    # show target class distribution\n",
        "    counts = dict(zip(*np.unique(y_train, return_counts=True)))\n",
        "    plt.bar([DSprites.Latents(k + (1 if with_shapes else 2)).name for k in counts.keys()], counts.values())\n",
        "    plt.title(f\"Distribution of fixed latents in {B:,} samples.\")\n",
        "    print(counts)\n",
        "\n",
        "    accuracies = []\n",
        "    for r in range(1, reps + 1):\n",
        "        print(f\"\\n\\n==========\\nExperiment {r}\")\n",
        "        linear_classifier = get_linear_classifier(num_classes=(5 if with_shapes else 4),\n",
        "                                                input_dim=(len(latent_subset) if latent_subset else LATENT_DIM))\n",
        "        # use this callback as a monitor - use an absurd number of epochs and stop\n",
        "        # only when the accuracy doesn't improve\n",
        "        until_convergence = tf.keras.callbacks.EarlyStopping(monitor='accuracy',\n",
        "                                                             min_delta=1e-5,\n",
        "                                                             patience=10)          \n",
        "        history = linear_classifier.fit(x_train, y_train,\n",
        "                                      batch_size=32, epochs=500,\n",
        "                                      callbacks=[until_convergence],\n",
        "                                      verbose=verbose)\n",
        "        accuracies.append(linear_classifier.evaluate(x_test, y_test)[-1])\n",
        "        \n",
        "    return np.array(accuracies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtEhauTFr5Im",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating $\\beta$-VAE's quantitative performance ($\\beta$ = 4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lRxNOZ5gJzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vae4_accs= run_experiment(vae4, ds, l=L, batches=B, test_batch=E, reps=REPEAT, with_shapes=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zt9mWJTKtVP4",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating VAE's quantitative performance ($\\beta$ = 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkEYpGPYhx_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vae1_accs = run_experiment(vae1, ds, l=L, batches=B, test_batch=E, reps=REPEAT, with_shapes=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6MWwIsMtc6U",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating untrained VAE's quantitative performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkSIFlakpjQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vaeu_accs = run_experiment(vae_untrained, ds, l=L, batches=B, test_batch=E, reps=REPEAT, with_shapes=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSde5JSRKQeP",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating PCA's quantitative performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rJlS-P_Iewg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca_accs= run_experiment(pca, ds, l=L, batches=B, test_batch=E, reps=REPEAT, with_shapes=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TQ2K5hN-nvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(vae4_accs)\n",
        "print(vae1_accs)\n",
        "print(vaeu_accs)\n",
        "print(pca_accs)\n",
        "\n",
        "print(np.mean(vae4_accs), np.std(vae4_accs))\n",
        "print(np.mean(vae1_accs), np.std(vae1_accs))\n",
        "print(np.mean(vaeu_accs), np.std(vaeu_accs))\n",
        "print(np.mean(pca_accs), np.std(pca_accs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRPVQNGB_5z7",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating $\\beta$-VAE's quantitative performance ($\\beta$ = 4) with shapes included"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVDsalxlAMSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vae4_accs_shapes = run_experiment(vae4, ds, l=L, batches=B, test_batch=E, reps=REPEAT, with_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuv1e4EDAPKB",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating VAE's quantitative performance ($\\beta$ = 1) with shapes included"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "162cwtIjAPa5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vae1_accs_shapes = run_experiment(vae1, ds, l=L, batches=B, test_batch=E, reps=REPEAT, with_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCQDZD_JAPos",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating untrained VAE's quantitative performance with shapes included"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBmWr0qbAPw6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vaeu_accs_shapes = run_experiment(vae_untrained, ds, l=L, batches=B, test_batch=E, reps=REPEAT, with_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qwgnPawKXZ6",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating PCA's quantitative with shapes included"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfV2q2VZKYwk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca_accs_shapes = run_experiment(pca, ds, l=L, batches=B, test_batch=E, reps=REPEAT, with_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BM1rRO4MA_DG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(vae4_accs_shapes)\n",
        "print(vae1_accs_shapes)\n",
        "print(vaeu_accs_shapes)\n",
        "print(pca_accs_shapes)\n",
        "\n",
        "print(np.mean(vae4_accs_shapes), np.std(vae4_accs_shapes))\n",
        "print(np.mean(vae1_accs_shapes), np.std(vae1_accs_shapes))\n",
        "print(np.mean(vaeu_accs_shapes), np.std(vaeu_accs_shapes))\n",
        "print(np.mean(pca_accs_shapes), np.std(pca_accs_shapes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8xTleg6lAJx",
        "colab_type": "text"
      },
      "source": [
        "# Qualitative measure\n",
        "\n",
        "In this section, the models are evaluated qualitativevly by observing the changes in latent activations ($z_i$) as we fix all but one generative latent factor. If the model disentangles generative factors well, the latent activation should be sensitive to (and only to) the corresponding fixed latent factor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYegProUrr0P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SAMPLE_SIZE = 500\n",
        "sample_latents = ds.sample_latent(SAMPLE_SIZE)\n",
        "\n",
        "def pos_latent_heatmap(model, sample_latents, dim):\n",
        "    lats = sample_latents.copy()\n",
        "    heatmap = np.full(\n",
        "        (ds.latent_size(DSprites.Latents.YPOS),\n",
        "         ds.latent_size(DSprites.Latents.XPOS)),\n",
        "        0, dtype=np.float32\n",
        "    )\n",
        "    for x in range(ds.latent_size(DSprites.Latents.XPOS)):\n",
        "        lats[:, DSprites.Latents.XPOS] = x\n",
        "        for y in range(ds.latent_size(DSprites.Latents.YPOS)):\n",
        "            lats[:, DSprites.Latents.YPOS] = y\n",
        "            z, mean, logvar = model.encode(ds.imgs[ds.to_idx(lats)])\n",
        "            z = z.numpy()\n",
        "            # notice how it's [y, x] since the rows represent the y-axis\n",
        "            heatmap[y, x] = np.mean(z[:, dim])\n",
        "    return heatmap\n",
        "\n",
        "def latent_activations(latent: DSprites.Latents, model, sample_latents, dim):\n",
        "    lats = sample_latents.copy()\n",
        "    square_idxs = lats[:, DSprites.Latents.SHAPE] == 0\n",
        "    oval_idxs = lats[:, DSprites.Latents.SHAPE] == 1\n",
        "    heart_idxs = lats[:, DSprites.Latents.SHAPE] == 2\n",
        "    assert (square_idxs | oval_idxs | heart_idxs).all()\n",
        "    scales = {'square': [], 'oval': [], 'heart': []}\n",
        "    for l in range(ds.latent_size(latent)):\n",
        "        lats[:, latent] = l\n",
        "        z, mean, logvar = model.encode(ds.imgs[ds.to_idx(lats)])\n",
        "        z = z.numpy()\n",
        "        scales['square'].append(np.mean(z[square_idxs, dim]))\n",
        "        scales['oval'].append(np.mean(z[oval_idxs, dim]))\n",
        "        scales['heart'].append(np.mean(z[heart_idxs, dim]))\n",
        "    return scales\n",
        "\n",
        "def latent_shape_activations(model, sample_latents, dim):\n",
        "    lats = sample_latents.copy()\n",
        "    shapes = [[], [], []]\n",
        "    for l in range(ds.latent_size(DSprites.Latents.SHAPE)):\n",
        "        lats[:, DSprites.Latents.SHAPE] = l\n",
        "        z, mean, logvar = model.encode(ds.imgs[ds.to_idx(lats)])\n",
        "        z = z.numpy()\n",
        "        shapes[l] = z[:, dim]\n",
        "    return {'square': shapes[0], 'oval': shapes[1], 'heart': shapes[2]}\n",
        "\n",
        "\n",
        "def vary_latent(seed_img, model: VAE, dim: int,\n",
        "                zmin: float=-2, zmax: float=2, step: float=1,\n",
        "                activation: typing.Callable[[tf.Tensor], tf.Tensor]=None) -> np.array:\n",
        "    \"\"\"\n",
        "    :param seed_img: image used as seed when varying latents. This image\n",
        "                     will be encoded by `model.encode(seed_img)` and the\n",
        "                     resulting `z` latent vector will be varied. Should be\n",
        "                     of shape (B, W, H, C).\n",
        "    :param model: VAE model used to encode and decode latents                     \n",
        "    :param dim: the dimension to vary. This value must be 0 <= dim < LATENT_DIM\n",
        "    :param zmin: determines the range of `z` to vary. `z` is varied starting from\n",
        "    `z[dim] + zmin` to `z[dim] + zmax`. Must be a negative value.\n",
        "    :param zmax: determines the range of `z` to vary. `z` is varied starting from\n",
        "    `z[dim] + zmin` to `z[dim] + zmax`. Must be a positive value.\n",
        "    :param step: the step size used to increment `z` when varying `z[dim]`.\n",
        "    :param activation: activation function to apply on\n",
        "                       `activation(model.decode(z))`. None applied if `None`\n",
        "                       (default).\n",
        "    :return: a numpy array of shape (N, B, W, H, C) where:\n",
        "              - N: number of total images generated when varying `z` according\n",
        "                   to `zmin`, `zmax`, `step`.\n",
        "                   That is, N = 1 + abs(zmax - zmin) // step\n",
        "              - B: batch size. This is the same as `seed_img.shape[0]`\n",
        "              - W: image width. This is the same as `seed_img.shape[1]`\n",
        "              - H: image height. This is the same as `seed_img.shape[2]`\n",
        "              - C: image channel. This is the same as `seed_img.shape[3]`\n",
        "    \"\"\"\n",
        "    assert zmin < 0 and zmax > 0\n",
        "    if not activation:\n",
        "        activation = lambda x: x\n",
        "    z, *_ = model.encode(seed_img)\n",
        "    z = z.numpy()\n",
        "    z[:, dim] += zmin\n",
        "    reconstructed = []\n",
        "    reconstructed.append(activation(model.decode(z)))\n",
        "    for _ in range(int(abs(zmax - zmin) // step)):\n",
        "        z[:, dim] += step\n",
        "        reconstructed.append(activation(model.decode(z)))\n",
        "    reconstructed = np.flip(np.array(reconstructed), axis=0)\n",
        "    return reconstructed\n",
        "\n",
        "def show_latents(model, dims: list, ds: DSprites,\n",
        "                 reconstruction_activation_function: typing.Callable[[tf.Tensor], tf.Tensor]=None,\n",
        "                 save: typing.Optional[str]=None):\n",
        "    \"\"\"\n",
        "    Plots figure 7 in Higgins et al. (2017)\n",
        "\n",
        "    :param model: Any model that has the `encode` and `decode` functions.\n",
        "            `encode` is required to return a 3-tuple\n",
        "            (z, _, _) where z is the latent vector.\n",
        "    :param dims: List of dimensions to visualise.\n",
        "    :param ds: DSprites dataset\n",
        "    :param reconstruction_activation_function: Activation function to apply on\n",
        "                                               `activation(model.decode(z))`.\n",
        "                                               None applied if `None` (default).\n",
        "\n",
        "    :param save: If not none, save to path indicated.\n",
        "    \"\"\"\n",
        "    nrows = 9\n",
        "    ncols = 5\n",
        "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10, 18))\n",
        "    ax = ax.flatten()\n",
        "    for i, dim in enumerate(dims):\n",
        "        ax[i].imshow(pos_latent_heatmap(model, sample_latents, dim=dim),\n",
        "                     cmap='RdBu_r', interpolation='bilinear')\n",
        "        ax[i].set_title(f\"$z_{dim}$\")\n",
        "        ax[i].title.set_fontsize(15)\n",
        "        ax[i].set_xticks(())\n",
        "        ax[i].set_yticks(())\n",
        "        if i % ncols == 0:\n",
        "            ax[i].set_ylabel(\"position\")\n",
        "            ax[i].yaxis.label.set_fontsize(15)\n",
        "        \n",
        "    for i, dim in enumerate(dims, i + 1):\n",
        "        scale = latent_activations(DSprites.Latents.SCALE, model,\n",
        "                                   sample_latents, dim=dim)\n",
        "        ax[i].plot(scale['oval'], color='green')\n",
        "        ax[i].plot(scale['heart'], color='blue')\n",
        "        ax[i].plot(scale['square'], color='red')\n",
        "        ax[i].set_xticks(())\n",
        "        ax[i].set_yticks(())\n",
        "        if i % ncols == 0:\n",
        "            ax[i].set_ylabel(\"scale\")\n",
        "            ax[i].yaxis.label.set_fontsize(15)\n",
        "    \n",
        "    for i, dim in enumerate(dims, i + 1):\n",
        "        scale = latent_activations(DSprites.Latents.ORIENTATION,\n",
        "                                   model, sample_latents, dim=dim)\n",
        "        ax[i].plot(scale['oval'], color='green')\n",
        "        ax[i].plot(scale['heart'], color='blue')\n",
        "        ax[i].plot(scale['square'], color='red')\n",
        "        ax[i].set_xticks(())\n",
        "        ax[i].set_yticks(())\n",
        "        if i % ncols == 0:\n",
        "            ax[i].set_ylabel(\"rotation\")\n",
        "            ax[i].yaxis.label.set_fontsize(15)\n",
        "\n",
        "    def draw_whisker(ax, data, colour):\n",
        "        p = ax.boxplot(data, patch_artist=True, showfliers=False)\n",
        "        for i, patch in enumerate(p['boxes']):\n",
        "            patch.set(facecolor='white', edgecolor=colour[i])\n",
        "\n",
        "    for i, dim in enumerate(dims, i + 1):\n",
        "        shape = latent_shape_activations(model, sample_latents, dim=dim)\n",
        "        draw_whisker(ax[i], [shape['oval'], shape['heart'], shape['square']],\n",
        "                     colour=['green', 'blue', 'red'])\n",
        "        ax[i].set_xticks(())\n",
        "        ax[i].set_yticks(())\n",
        "        if i % ncols == 0:\n",
        "            ax[i].set_ylabel(\"shape\")\n",
        "            ax[i].yaxis.label.set_fontsize(15)\n",
        "\n",
        "    seed_img = ds.sample_latent(1)\n",
        "    # show ovals\n",
        "    seed_img[:, DSprites.Latents.SHAPE] = 1\n",
        "    seed_img = ds.imgs[ds.to_idx(seed_img)]\n",
        "    for i, dim in enumerate(dims, i + 1):\n",
        "        # we're only varying the latent of one seed_img, squeeze axis=1\n",
        "        # to get shape (N, W, H, C) where N = num images generated by varying\n",
        "        # latents, W = width, H = height, C = channels\n",
        "        recon =  vary_latent(seed_img, model, dim=dim,\n",
        "                             activation=reconstruction_activation_function).squeeze(axis=1)\n",
        "        for j in range(recon.shape[0]):\n",
        "            ax[i + j * 5].imshow(recon[j].squeeze(), cmap='gray', interpolation='nearest')\n",
        "            ax[i + j * 5].set_xticks(())\n",
        "            ax[i + j * 5].set_yticks(())\n",
        "\n",
        "    fig.subplots_adjust(wspace=0.1, hspace=0.1)\n",
        "    square_patch = mpatches.Patch(color='red', label='Square')\n",
        "    heart_patch = mpatches.Patch(color='blue', label='Heart')\n",
        "    oval_patch = mpatches.Patch(color='green', label='Oval')\n",
        "    plt.legend(handles=[square_patch, heart_patch, oval_patch], loc='lower center',\n",
        "               bbox_to_anchor=(-0.1, -0.35), ncol=3)\n",
        "    if save: plt.savefig(save)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m56XpxZT9NUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_latents(vae4, dims=[9, 8, 0, 5, 6], ds=ds, reconstruction_activation_function=tf.nn.sigmoid, save=\"beta4.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXzlJr4RjwTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_latents(vae1, dims=[0, 4, 6, 8, 9], ds=ds, reconstruction_activation_function=tf.nn.sigmoid, save=\"beta1.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCzyzFLpoVug",
        "colab_type": "text"
      },
      "source": [
        "# Thoughts on the $\\beta$-VAE metric\n",
        "\n",
        "\n",
        "Intuitively, $\\mathbf z_{\\text{diff}}$ is expected to be close to 0 at the dimension where the generative factor is kept fixed. Here, we plot all 10 dimensions of $\\mathbf z_{\\text{diff}}$ and observe that it is indeed the case for most of the generative factors.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emz36SjWaeDO",
        "colab_type": "code",
        "outputId": "dc142db1-85b4-4c8f-ad14-785d599b171b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "zdiff, target = generate_benchmarking_dataset(vae4, ds, L, 1000, with_shapes=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:32<00:00, 30.72it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlg5LdO8bsE7",
        "colab_type": "code",
        "outputId": "4d3c99dd-cbf4-48c8-eddc-ebd95a9b088d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "# 0, 5, 6, 8, 9 are the latent dimensions corresponding to scale, rot, rot, xpos, and ypos\n",
        "data = []\n",
        "\n",
        "for i in range(5):\n",
        "    data.append(zdiff[target == i])\n",
        "fig, ax = plt.subplots(1, 5, figsize=(20, 4), sharey=True)\n",
        "ax = ax.flatten()\n",
        "\n",
        "box_params = dict(linewidth=1.5,\n",
        "                  facecolor='white',\n",
        "                  edgecolor=\"#f54242\")\n",
        "\n",
        "for i in range(5):\n",
        "    ax[i].set_title(str(DSprites.Latents(i + 1).name).title())\n",
        "    p = ax[i].boxplot(data[i], showfliers=False, patch_artist=True)\n",
        "    for patch in p['boxes']:\n",
        "        patch.set(facecolor='white', edgecolor='black')\n",
        "    if i == 1: p['boxes'][0].set(**box_params)\n",
        "    if i == 2:\n",
        "        p['boxes'][5].set(**box_params)\n",
        "        p['boxes'][6].set(**box_params)\n",
        "    if i == 3: p['boxes'][8].set(**box_params)\n",
        "    if i == 4: p['boxes'][9].set(**box_params)\n",
        "\n",
        "    ax[i].set_xticklabels(range(10))\n",
        "    if i == 2: ax[i].set_xlabel(\"Latent dimension $z_i$\")\n",
        "    if i == 0: ax[i].set_ylabel(r\"$z_{diff}$\")\n",
        "plt.savefig(\"latent_activation_discovery.pdf\")\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABJEAAAEaCAYAAAChAcYOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1440x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2ZQvvWYosHX",
        "colab_type": "text"
      },
      "source": [
        "## Observation 1\n",
        "When the linear classifier is tasked with classifying 4 classes: scale, orientation, xpos, ypos, it achieves 100% accuracy easily as scale, xpos, and ypos have categorically lower $\\mathbf z_{\\text{diff}}$ values in their respective dimensions. To correctly classify the remaining class, orientation, the classifier has to simply identify the cases when none of these dimensions have values close to 0. Proof of this behaviour can be seen in Obs. 3.\n",
        "\n",
        "## Observation 2\n",
        "In other words, if we included shape as the 5th class for the classifier to predict, we expect to see a drop in accuracy as it can no longer easily distinguish between orientation and shape. If it follows the strategy in Obs. 1, it could go either way: shape or orientation. See confusion matrix/heatmap to see misclassifications.\n",
        "\n",
        "## Observation 3\n",
        "Observation 1 leads to another hypothesis, if we used just 3 dimensions (features) [0, 8, 9] and task the classifier with predicting the 4 classes as the authors did, we can still acheive 100% accuracy. All it has to do is identify when all 3 dimensions are non-zero to predict orientation!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB4ge1h5ll6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contrived_example_accs = run_experiment(vae4, ds, l=L, batches=B, test_batch=E, reps=REPEAT, with_shapes=False, latent_subset=[0, 8, 9])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iByJpRbxtvDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contrived_example_accs\n",
        "print(np.mean(contrived_example_accs))\n",
        "print(np.std(contrived_example_accs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3Fi0Jz12EYg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "c3f66fd3-409e-4807-a76f-744658daea1d"
      },
      "source": [
        "x_train, y_train = generate_benchmarking_dataset(vae4, ds, l=L, batches=(B + E), with_shapes=True)\n",
        "x_train = x_train[: B]\n",
        "y_train = y_train[: B]\n",
        "x_test = x_train[-E:]\n",
        "y_test = y_train[-E:]\n",
        "\n",
        "linear_classifier = get_linear_classifier(num_classes=5)\n",
        "until_convergence = tf.keras.callbacks.EarlyStopping(monitor='accuracy',\n",
        "                                                     min_delta=1e-5,\n",
        "                                                     patience=10)          \n",
        "history = linear_classifier.fit(x_train, y_train,\n",
        "                              batch_size=32, epochs=500,\n",
        "                              callbacks=[until_convergence],\n",
        "                              verbose=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 15000/15000 [07:48<00:00, 32.03it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 10000 samples\n",
            "Epoch 1/500\n",
            "10000/10000 [==============================] - 1s 78us/sample - loss: 1.6380 - accuracy: 0.3597\n",
            "Epoch 2/500\n",
            "10000/10000 [==============================] - 1s 64us/sample - loss: 1.4944 - accuracy: 0.2913\n",
            "Epoch 3/500\n",
            "10000/10000 [==============================] - 1s 63us/sample - loss: 1.4266 - accuracy: 0.3077\n",
            "Epoch 4/500\n",
            "10000/10000 [==============================] - 1s 66us/sample - loss: 1.3757 - accuracy: 0.3202\n",
            "Epoch 5/500\n",
            "10000/10000 [==============================] - 1s 64us/sample - loss: 1.3339 - accuracy: 0.4091\n",
            "Epoch 6/500\n",
            "10000/10000 [==============================] - 1s 64us/sample - loss: 1.2984 - accuracy: 0.5894\n",
            "Epoch 7/500\n",
            "10000/10000 [==============================] - 1s 65us/sample - loss: 1.2672 - accuracy: 0.7495\n",
            "Epoch 8/500\n",
            "10000/10000 [==============================] - 1s 65us/sample - loss: 1.2394 - accuracy: 0.7941\n",
            "Epoch 9/500\n",
            "10000/10000 [==============================] - 1s 64us/sample - loss: 1.2144 - accuracy: 0.8117\n",
            "Epoch 10/500\n",
            "10000/10000 [==============================] - 1s 65us/sample - loss: 1.1915 - accuracy: 0.8090\n",
            "Epoch 11/500\n",
            "10000/10000 [==============================] - 1s 66us/sample - loss: 1.1706 - accuracy: 0.8109\n",
            "Epoch 12/500\n",
            "10000/10000 [==============================] - 1s 63us/sample - loss: 1.1512 - accuracy: 0.8126\n",
            "Epoch 13/500\n",
            "10000/10000 [==============================] - 1s 64us/sample - loss: 1.1331 - accuracy: 0.8178\n",
            "Epoch 14/500\n",
            "10000/10000 [==============================] - 1s 63us/sample - loss: 1.1163 - accuracy: 0.8149\n",
            "Epoch 15/500\n",
            "10000/10000 [==============================] - 1s 63us/sample - loss: 1.1005 - accuracy: 0.8139\n",
            "Epoch 16/500\n",
            "10000/10000 [==============================] - 1s 64us/sample - loss: 1.0856 - accuracy: 0.8136\n",
            "Epoch 17/500\n",
            "10000/10000 [==============================] - 1s 63us/sample - loss: 1.0716 - accuracy: 0.8123\n",
            "Epoch 18/500\n",
            "10000/10000 [==============================] - 1s 64us/sample - loss: 1.0583 - accuracy: 0.8117\n",
            "Epoch 19/500\n",
            "10000/10000 [==============================] - 1s 64us/sample - loss: 1.0457 - accuracy: 0.8164\n",
            "Epoch 20/500\n",
            "10000/10000 [==============================] - 1s 63us/sample - loss: 1.0338 - accuracy: 0.8107\n",
            "Epoch 21/500\n",
            "10000/10000 [==============================] - 1s 66us/sample - loss: 1.0224 - accuracy: 0.8098\n",
            "Epoch 22/500\n",
            "10000/10000 [==============================] - 1s 65us/sample - loss: 1.0115 - accuracy: 0.8081\n",
            "Epoch 23/500\n",
            "10000/10000 [==============================] - 1s 62us/sample - loss: 1.0011 - accuracy: 0.8086\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvlyI-fmuM8k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "1add0076-f52b-44e9-cfe5-a398618e928c"
      },
      "source": [
        "preds = linear_classifier.predict(x_test)\n",
        "preds = np.argmax(preds, axis=1)\n",
        "conf_mat = np.empty(shape=(5, 5), dtype=np.uint8)\n",
        "for t in range(5):\n",
        "    for p in range(5):\n",
        "        conf_mat[t, p] = np.sum((y_test == t) & (preds == p))\n",
        "fig = plt.figure(figsize=(12, 7))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "img = ax.imshow(conf_mat, cmap='magma_r') # or magma_r?\n",
        "ax.set_xlabel(\"Predicted labels\")\n",
        "ax.set_ylabel(\"True labels\")\n",
        "ax.set_xticks(range(5))\n",
        "ax.set_yticks(range(5))\n",
        "ax.set_xticklabels([DSprites.Latents(i + 1).name.title() for i in range(5)])\n",
        "ax.set_yticklabels([DSprites.Latents(i + 1).name.title() for i in range(5)])\n",
        "ax.yaxis.label.set_fontsize(15)\n",
        "ax.xaxis.label.set_fontsize(15)\n",
        "ax.tick_params(labelsize=12)\n",
        "ax.set_title(r\"Confusion matrix of linear classifier trained on $\\beta$ = 4 VAE\", y=1.08,\n",
        "             fontdict={'fontsize': 15})\n",
        "fig.colorbar(img)\n",
        "ax.xaxis.tick_top()\n",
        "plt.savefig(\"confusion_matrix.png\");"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHQCAYAAABdgUsJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5lHjM09W9hg",
        "colab_type": "text"
      },
      "source": [
        "# Questions:\n",
        "\n",
        "1. Each batch allowed different fixed latent $y$?\n",
        "    - currently: test set of 5000 points. The entire batch is considered the test set. In other words, there's only one batch (of size 5000)\n",
        "2. What's the value of **L** and **B**?\n",
        "    - currently: **L** = 32 and **B** = 5000\n",
        "3. How about repeating experiments 30 times to get the same number of scores as the paper? Would it even help? It's probably stable enough to take less than 30.\n",
        "    - currently: 1 model trained + 3 repetitions when evaluating quantitative performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpdWGBeis5ll",
        "colab_type": "text"
      },
      "source": [
        "# TODO:\n",
        "\n",
        "1. ~repeat accuracy measure x number of times (see how paper implements it)~\n",
        "2. ~include SHAPE latent in the accuracy measure. I.e. 5 classes instead of 4~\n",
        "3. ~reproduce the plot that analyses the activation of $z_i$s based on varying generative latents~\n",
        "4. ~PCA and ICA~\n",
        "5. reproduce the plot that analyses the accuracy of each of the latents independently. Read why they argue that this is does not measure the independence.\n",
        "6. Validate this claim from Higgins et al. (2017):\n",
        "> For the 2D shapes dataset, we have found that the optimal values of $\\beta$ as determined by visual inspection match closely the optimal values as determined by the disentanglement metric.\n",
        "7. ~Instead of using the accuracy on the training set, use 10,000 points for training and 5,000 for testing (which gives the final accuracy) - see other paper (L = 64 in both cases).~\n",
        "8. There are 5 other metrics to test - see other paper.\n",
        "9. Try on other labelled synthetic datasets (esp. noisy dSprites, 3D Shapes etc.) - see other paper.\n",
        "10. Try factor-VAE?"
      ]
    }
  ]
}