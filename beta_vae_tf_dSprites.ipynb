{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "beta_vae_tf_dSprites.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5thJEd4HpTYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import typing\n",
        "import math\n",
        "import tqdm\n",
        "import os\n",
        "import itertools\n",
        "import uuid\n",
        "import copy\n",
        "import subprocess\n",
        "import imageio\n",
        "import IPython\n",
        "\n",
        "\n",
        "from IPython import display\n",
        "from IPython.display import Image\n",
        "from pathlib import Path\n",
        "from enum import IntEnum"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXHlL49qpW0_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DSprites:\n",
        "    class Latents(IntEnum):\n",
        "        COLOUR, SHAPE, SCALE, ORIENTATION, XPOS, YPOS = range(6)\n",
        "        \n",
        "    \"\"\"\n",
        "    A significant portion of this class is taken as-is from the manual\n",
        "    https://github.com/deepmind/dsprites-dataset/blob/master/dsprites_reloading_example.ipynb\n",
        "    \"\"\"\n",
        "    def __init__(self, path=\".\", download=False):\n",
        "        self._filename = 'dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz'\n",
        "        path = Path(path).absolute()\n",
        "        assert path.exists()\n",
        "        data = path / self._filename\n",
        "        if not data.exists():\n",
        "            if download:\n",
        "                subprocess.run([\"wget\", \"-O\", str(data),\n",
        "                                \"https://github.com/deepmind/dsprites-dataset/raw/master/dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz\"])\n",
        "            else:\n",
        "                raise ValueException(\"Can't find dataset, use download=True to download.\")\n",
        "        data = np.load(str(data), encoding='bytes', allow_pickle=True)\n",
        "\n",
        "        # ====\n",
        "\n",
        "        imgs = data['imgs']\n",
        "        metadata_raw = data['metadata'][()]\n",
        "        self._metadata = dict()\n",
        "        for k, v in metadata_raw.items():\n",
        "            self._metadata[k.decode()] = v\n",
        "\n",
        "        # NOTE: can't cast now because our notebook runs out of RAM. cast in map instead\n",
        "        # imgs = imgs.reshape(-1, 64, 64, 1).astype(np.float32)\n",
        "        self._imgs = imgs.reshape(-1, 64, 64, 1)\n",
        "\n",
        "        # for example: array([ 0,  0,  2, 37, 15, 22])\n",
        "        # i.e. the relative (normalised) change in latent factors\n",
        "        self._latents_classes = data['latents_classes']\n",
        "\n",
        "        # for example: array([1., 1., 0.7 , 5.96097068, 0.48387097, 0.70967742])\n",
        "        # i.e. the actual latent values used to generate the image\n",
        "        self._latents_values = data['latents_values']\n",
        "\n",
        "        # specification: the number of varying \"degrees\" of change in each\n",
        "        # dimension corresponding to an independent generative factor\n",
        "        # array([ 1,        3,      6,           40,  32,  32])\n",
        "        #       colour, shape,  scale,  orientation,   X,   Y\n",
        "        self._latents_sizes = self._metadata['latents_sizes']\n",
        "\n",
        "        # for easy conversion from latent vector to indices later (see latent_to_idx)\n",
        "        # essentially: array([737280, 245760,  40960,   1024,     32,      1])\n",
        "        self._latents_bases = np.r_[self._latents_sizes[::-1].cumprod()[::-1][1:], 1]\n",
        "    \n",
        "    def latent_size(self, latent: 'DSprites.Latents') -> int:\n",
        "        \"\"\"\n",
        "        :param latent: of type DSprites.Latents (an enum class)\n",
        "        :return: the maximum integer allowed for the specified `latent`\n",
        "        \"\"\"\n",
        "        return self._latents_sizes[latent.value]\n",
        "    \n",
        "    def to_idx(self, latents: np.array) -> int:\n",
        "        \"\"\"\n",
        "        convert latent vector into index that can then be used to index\n",
        "        the actual image in self._imgs\n",
        "        \"\"\"\n",
        "        return np.dot(latents, self._latents_bases).astype(int)\n",
        "    \n",
        "    def sample_latent(self, n: int=1, fixed: 'DSprites.Latents'=None) -> np.array:\n",
        "        \"\"\"\n",
        "        randomly samples `n` latent vectors\n",
        "\n",
        "        :param n: number samples\n",
        "        :param fixed: if not `None`, then in all samples, this latent is kept\n",
        "                     fixed based on a random draw. The rest of the latents are\n",
        "                     random.\n",
        "        :return: an `np.array` of shape nx6\n",
        "        \"\"\"\n",
        "        samples = np.zeros((n, self._latents_sizes.shape[0]))\n",
        "        for i, lat_size in enumerate(self._latents_sizes):\n",
        "            samples[:, i] = np.random.randint(lat_size, size=n)\n",
        "        if fixed:\n",
        "            samples[:, fixed] = np.random.randint(0, ds.latent_size(fixed))\n",
        "        return samples\n",
        "    \n",
        "    @property\n",
        "    def imgs(self) -> np.array:\n",
        "        return self._imgs\n",
        "\n",
        "    def subset(self, size=50_000) -> np.array:\n",
        "        \"\"\"\n",
        "        returns a subset of the images. (Workaround for memory constraints)\n",
        "        :param size: number of samples to return\n",
        "        \"\"\"\n",
        "        return self._imgs[np.random.choice(self._imgs.shape[0], size=size, replace=False)]\n",
        "\n",
        "def make_grid(tensor: np.array, nrow: int=8, padding: int=2, pad_value: int=0) -> np.array:\n",
        "    \"\"\"\n",
        "    adapted from: https://pytorch.org/docs/stable/_modules/torchvision/utils.html#make_grid\n",
        "    :param tensor: nxwxhxc np.array\n",
        "    :param nrow: number of rows to use.\n",
        "    :param padding: padding between images\n",
        "    :param pad_value: value used to pad\n",
        "    :return: np.array of dimension 3 (WxHxC) with all images arranged in a grid.\n",
        "\n",
        "    \"\"\"\n",
        "    if tensor.shape[0] == 1:\n",
        "        return tensor.squeeze()\n",
        "\n",
        "    # make the mini-batch of images into a grid\n",
        "    nmaps = tensor.shape[0]\n",
        "    xmaps = min(nrow, nmaps)\n",
        "    ymaps = int(math.ceil(float(nmaps) / xmaps))\n",
        "    height, width = int(tensor.shape[1] + padding), int(tensor.shape[2] + padding)\n",
        "    num_channels = tensor.shape[3]\n",
        "    grid = np.full((height * ymaps + padding, width * xmaps + padding, num_channels), pad_value, dtype=tensor.dtype)\n",
        "    k = 0\n",
        "    for y in range(ymaps):\n",
        "        for x in range(xmaps):\n",
        "            if k >= nmaps: break\n",
        "            ystart = y * height + padding\n",
        "            xstart = x * width + padding\n",
        "            grid[ystart:(ystart + height - padding), ...][:, xstart:(xstart + width - padding), :] = tensor[k]\n",
        "            k = k + 1\n",
        "    return grid.squeeze()\n",
        "\n",
        "def imshow(img: np.array, title: str='', ax: plt.Axes=None):\n",
        "    if not ax:\n",
        "        fig = plt.figure(figsize=(15, 15))\n",
        "        ax = fig.add_subplot(111)\n",
        "    ax.imshow(img, cmap='gray', interpolation='nearest')\n",
        "    ax.set_xticks(())\n",
        "    ax.set_yticks(())\n",
        "    if title:\n",
        "        ax.set_title(title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJ0d-d1ZrfXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds = DSprites(download=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7j8R6wJwwG3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imshow(make_grid(ds.imgs[ds.to_idx(ds.sample_latent(32))]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtWZe4tIwa-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_latents = ds.sample_latent(32, fixed=DSprites.Latents.SHAPE)\n",
        "imshow(make_grid(ds.imgs[ds.to_idx(random_latents)]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvjCSJNzpiiZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def criterion(x, x_recon, mean, logvar, beta=1.0, lhd='bernoulli'):\n",
        "    \"\"\"\n",
        "    x - original image\n",
        "    x_recon - LOGITS! depending on `lhd`, it'll either be activated by sigmoid\n",
        "              or a normal distribution\n",
        "    \"\"\"\n",
        "    kl = -0.5 * tf.reduce_sum(1 + logvar - mean**2 - tf.exp(logvar))\n",
        "    if lhd.lower() == 'bernoulli':\n",
        "        lh = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(logits=x_recon, labels=x))\n",
        "    elif lhd.lower() == 'normal':\n",
        "        # TODO!\n",
        "        raise NotImplementedError\n",
        "    else:\n",
        "        raise ValueError(f\"Expected lhd to be one of bernoulli or normal, got {lhd}.\")\n",
        "    return (lh + beta * kl) / x.shape[0]\n",
        "\n",
        "def get_step_function():\n",
        "    @tf.function\n",
        "    def step(model, x, optimiser, beta, lhd):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z, mean, logvar = model.encode(x)\n",
        "            x_recon = model.decode(z)\n",
        "            loss = criterion(x, x_recon, mean, logvar, beta, lhd)\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        optimiser.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "        return loss\n",
        "    return step\n",
        "    \n",
        "def train_model(model, epochs, train, optimiser, beta, lhd='bernoulli'):\n",
        "    # redefine step function because it's a compiled graph (bug)\n",
        "    # see: https://github.com/tensorflow/tensorflow/issues/27120\n",
        "    step = get_step_function()\n",
        "    rtqdm = tqdm.trange(epochs)\n",
        "    losses = []\n",
        "    for e in rtqdm:\n",
        "        epochs_losses = []\n",
        "        for x in train:\n",
        "            epochs_losses.append(step(model, x, optimiser, beta, lhd))\n",
        "        losses.append(np.mean(epochs_losses))\n",
        "        rtqdm.set_postfix(loss=losses[-1])\n",
        "    return losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyQs7vpf21KW",
        "colab_type": "text"
      },
      "source": [
        "# Build a model according to specification (Tbl. 1 Higgins et al.)\n",
        "* **Input**  4096 (flattened 64x64x1).\n",
        "* **Encoder**  FC 1200, 1200. ReLU activation.\n",
        "* **Latents**  10\n",
        "* **Decoder**  FC 1200, 1200, 1200, 4096. Tanh activation. Bernoulli.\n",
        "* **Optimiser** Adagrad 1e-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7Vp7MKTwZ3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VAE(tf.keras.Model):\n",
        "    def __init__(self, latent_dim=10):\n",
        "        super(VAE, self).__init__()\n",
        "        self._latent_dim = latent_dim\n",
        "        self.encoder = tf.keras.Sequential([\n",
        "            tf.keras.layers.InputLayer((64, 64, 1)),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(1200, activation='relu'),\n",
        "            tf.keras.layers.Dense(1200, activation='relu'),\n",
        "            tf.keras.layers.Dense(latent_dim * 2)\n",
        "        ])\n",
        "        self.decoder = tf.keras.Sequential([\n",
        "            tf.keras.layers.InputLayer(latent_dim),\n",
        "            tf.keras.layers.Dense(1200, activation='tanh'),\n",
        "            tf.keras.layers.Dense(1200, activation='tanh'),\n",
        "            tf.keras.layers.Dense(1200, activation='tanh'),\n",
        "            tf.keras.layers.Dense(4096),\n",
        "            tf.keras.layers.Reshape((64, 64, 1))\n",
        "        ])\n",
        "\n",
        "    def call(self, x): raise NotImplementedError\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = self.encoder(x)\n",
        "        mean, logvar = tf.split(h, num_or_size_splits=2, axis=1)\n",
        "        return self.reparameterise(mean, logvar), mean, logvar\n",
        "    \n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    @staticmethod\n",
        "    def reparameterise(mean, logvar):\n",
        "        # log sig^2 = 2 log sig => exp(1/2 log sig^2) = exp(log sig) = sig\n",
        "        eps = tf.random.normal(mean.shape, mean=0.0, stddev=1.0)\n",
        "        return mean + tf.exp(logvar * 0.5) * eps\n",
        "\n",
        "BETA = 4\n",
        "EPOCHS = 25\n",
        "LATENT_DIM = 10\n",
        "BATCH_SIZE = 32\n",
        "TR_SIZE = 400_000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZh_ZdbK592q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cast_dtype(x):\n",
        "    return tf.cast(x, tf.float32)\n",
        "\n",
        "vae4 = VAE(latent_dim=LATENT_DIM)\n",
        "train = tf.data.Dataset.from_tensor_slices(ds.subset(size=TR_SIZE))\n",
        "train = (train\n",
        "         .map(cast_dtype)\n",
        "         .shuffle(2**10)\n",
        "         .batch(BATCH_SIZE))\n",
        "losses4 = train_model(vae4, EPOCHS,\n",
        "                      train, tf.keras.optimizers.Adagrad(learning_rate=1e-2),\n",
        "                      beta=BETA, lhd='bernoulli')\n",
        "plt.plot(losses4)\n",
        "plt.title(\"Average epoch loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"ELBO loss\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWSilQiAAAd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = ds.subset(size=32)\n",
        "z, *_= vae4.encode(x)\n",
        "x_recon = tf.nn.sigmoid(vae4.decode(z)).numpy()\n",
        "fig = plt.figure(figsize=(20, 20))\n",
        "ax1 = fig.add_subplot(121)\n",
        "ax2 = fig.add_subplot(122)\n",
        "imshow(make_grid(x), title='Original', ax=ax1)\n",
        "imshow(make_grid(x_recon), title='Reconstructed', ax=ax2)\n",
        "fig.subplots_adjust(wspace=0.01)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSIFLEMRQxqI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weight_file = f'./vae4/vae4_e{EPOCHS}_{TR_SIZE}'\n",
        "vae4.save_weights(weight_file)\n",
        "# to load:\n",
        "# vae4 = VAE(LATENT_DIM)\n",
        "# vae4.load_weights(weight_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tzeoy5hqUcny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vae1 = VAE(latent_dim=LATENT_DIM)\n",
        "losses1 = train_model(vae1, EPOCHS,\n",
        "                      train, tf.keras.optimizers.Adagrad(learning_rate=1e-2),\n",
        "                      beta=1, lhd='bernoulli')\n",
        "plt.plot(losses1, label='beta=1')\n",
        "plt.plot(losses4, label='beta=4')\n",
        "plt.title(\"Average epoch loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"ELBO loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3fUQNLlUxB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weight_file = f'./vae1/vae1_e{EPOCHS}_{TR_SIZE}'\n",
        "vae1.save_weights(weight_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X62jBqmXip_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z, *_= vae1.encode(x)\n",
        "x_recon = tf.nn.sigmoid(vae1.decode(z)).numpy()\n",
        "fig = plt.figure(figsize=(20, 20))\n",
        "ax1 = fig.add_subplot(121)\n",
        "ax2 = fig.add_subplot(122)\n",
        "imshow(make_grid(x), title='Original', ax=ax1)\n",
        "imshow(make_grid(x_recon), title='Reconstructed', ax=ax2)\n",
        "fig.subplots_adjust(wspace=0.01)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7y5LfkaddoRu",
        "colab_type": "text"
      },
      "source": [
        "# Visualising latents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYFe7r1ndp1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LatentVisualiser:\n",
        "    def __init__(self, model: tf.keras.Model, dim: int=0,\n",
        "                 init_latent: tf.Tensor=None, width: int=8,\n",
        "                 height: int=8):\n",
        "        assert dim < LATENT_DIM \n",
        "        if init_latent is not None:\n",
        "            self._rnd = tf.identity(init_latent)\n",
        "        else:\n",
        "            self._rnd = tf.convert_to_tensor(np.random.normal(0, 1, rnd_shape), dtype=tf.float32)\n",
        "        self._dim = dim\n",
        "        self._filenames = []\n",
        "        self._model = model\n",
        "        self._width = width\n",
        "        self._height = height\n",
        "\n",
        "    def __call__(self, iters: int, step: float, save: str=None):\n",
        "        crnd = self._rnd.numpy().copy()\n",
        "        for i in range(1, iters + 1):\n",
        "            crnd[:, self._dim] += step\n",
        "            recon = tf.nn.sigmoid(self._model.decode(tf.convert_to_tensor(crnd))).numpy()\n",
        "            fig = plt.figure(figsize=(self._width, self._height))\n",
        "            ax = fig.add_subplot(111)\n",
        "            # hacky!: to prevent similar filenames\n",
        "            filename = f'{uuid.uuid4().hex}.png'\n",
        "            imshow(make_grid(recon), title=f\"Dimension {self._dim}: {i * step:0.4f}\", ax=ax)\n",
        "            fig.savefig(filename, bbox_inches='tight')\n",
        "            self._filenames.append(filename)\n",
        "            plt.close()\n",
        "        output_filename = save if save else \"_temp.gif\"\n",
        "        assert output_filename.endswith(\".gif\")\n",
        "        self._generate_fig(output_filename)\n",
        "        # with open(output_filename,'rb') as f:\n",
        "        #     display.display(Image(data=f.read(), format='png'))\n",
        "        return output_filename\n",
        "\n",
        "    def _generate_fig(self, output_filename):\n",
        "        assert len(self._filenames)\n",
        "        # taken from https://www.tensorflow.org/tutorials/generative/cvae#generate_a_gif_of_all_the_saved_images\n",
        "        with imageio.get_writer(output_filename, mode='I') as writer:\n",
        "            last = -1\n",
        "            for i, filename in enumerate(self._filenames):\n",
        "                frame = 2*(i**0.5)\n",
        "                if round(frame) > round(last): last = frame\n",
        "                else: continue\n",
        "                image = imageio.imread(filename)\n",
        "                writer.append_data(image)\n",
        "            image = imageio.imread(filename)\n",
        "            writer.append_data(image)\n",
        "    \n",
        "    @staticmethod\n",
        "    def combine_gifs(filenames: typing.List[str], output: str, cols: int) -> str:\n",
        "        # rows = math.ceil(len(filenames) / cols)\n",
        "        assert len(filenames) % cols == 0\n",
        "        rows = int(len(filenames) / cols)\n",
        "        gifs = [imageio.get_reader(f) for f in filenames]\n",
        "        frames = gifs[0].get_length()\n",
        "        assert all(g.get_length() == frames for g in gifs)\n",
        "        gifs = itertools.cycle(gifs)\n",
        "\n",
        "        with imageio.get_writer(output, mode='I') as writer:\n",
        "            for _ in range(frames):\n",
        "                # buf = [[] for _ in range(rows)]\n",
        "                buf = []\n",
        "                for row in range(rows):\n",
        "                    row_buffer = [next(gifs).get_next_data() for _ in range(cols)]\n",
        "                    buf.append(np.hstack(row_buffer))\n",
        "                new_image = np.vstack(buf)\n",
        "                writer.append_data(new_image)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ds2zJaXdyuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ITERS = 30\n",
        "STEP = 0.25\n",
        "\n",
        "# rnd = tf.convert_to_tensor(np.random.normal(0, 1, size=(32, LATENT_DIM)), dtype=tf.float32)\n",
        "rnd, *_ = vae4.encode(x)\n",
        "\n",
        "gifs = []\n",
        "for dim in range(0, LATENT_DIM):\n",
        "    # model with beta=4\n",
        "    gifs.append(LatentVisualiser(vae4, dim=dim, init_latent=rnd)(iters=ITERS, step=STEP, save=f\"beta4_dim{dim}.gif\"))\n",
        "\n",
        "LatentVisualiser.combine_gifs(gifs, \"beta4.gif\", 2)\n",
        "with open(\"beta4.gif\",'rb') as f:\n",
        "    display.display(Image(data=f.read(), format='png'))\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpUgpvZrekW9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ITERS = 30\n",
        "STEP = -0.25\n",
        "\n",
        "gifs = []\n",
        "for dim in range(0, LATENT_DIM):\n",
        "    # model with beta=4\n",
        "    gifs.append(LatentVisualiser(vae4, dim=dim, init_latent=rnd)(iters=ITERS, step=STEP, save=f\"beta4_dim{dim}_n.gif\"))\n",
        "\n",
        "LatentVisualiser.combine_gifs(gifs, \"beta4_n.gif\", 2)\n",
        "with open(\"beta4_n.gif\",'rb') as f:\n",
        "    display.display(Image(data=f.read(), format='png'))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}